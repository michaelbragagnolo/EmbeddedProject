{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01922531",
   "metadata": {},
   "source": [
    "***\n",
    "## Training strategies\n",
    "\n",
    "Experiment that defines the **training strategies for the VAE model and Generative Replay**.\n",
    "\n",
    "*Code is based on the SupervisedTemplate of Avalanche:*\n",
    " - https://avalanche-api.continualai.org/en/v0.2.0/generated/avalanche.training.templates.SupervisedTemplate.html?highlight=supervised#avalanche.training.templates.SupervisedTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c052f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LIBRARIES AND UTILS ---\n",
    "from typing import Optional, Sequence, List, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module, CrossEntropyLoss\n",
    "from torch.optim import Optimizer, SGD\n",
    "\n",
    "import avalanche\n",
    "from avalanche.training.templates.base import BaseTemplate\n",
    "from avalanche.training.templates.supervised import SupervisedTemplate\n",
    "from avalanche.training.plugins import (SupervisedPlugin, GenerativeReplayPlugin, EvaluationPlugin, TrainGeneratorAfterExpPlugin)\n",
    "from avalanche.training.plugins.evaluation import default_evaluator\n",
    "\n",
    "from avalanche.logging import InteractiveLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa43dcb",
   "metadata": {},
   "source": [
    "***\n",
    "### VAE training class\n",
    "\n",
    "Experiment that defines the training strategies for the **VAE model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8555c206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the VAE generative model and its loss function\n",
    "from imports.GenerativeModel import VAE_model, VAE_loss\n",
    "\n",
    "class VAE_TrainingStrategy(SupervisedTemplate):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # --- Strategy instantiation --- # \n",
    "        # 1. Model\n",
    "        # 2. Optimizer\n",
    "        # 3. Criterion\n",
    "        model: Module, optimizer: Optimizer, criterion=VAE_loss,\n",
    "        # additional arguments\n",
    "        train_mb_size: int = 1,\n",
    "        train_epochs: int = 1,\n",
    "        eval_mb_size: int = None,\n",
    "        device=None,\n",
    "        plugins: Optional[List[SupervisedPlugin]] = None,\n",
    "        evaluator: EvaluationPlugin = EvaluationPlugin(\n",
    "            loggers=[InteractiveLogger()],\n",
    "            suppress_warnings=True,),\n",
    "        eval_every=-1,\n",
    "        **base_kwargs):\n",
    "\n",
    "        super().__init__(\n",
    "            model, optimizer, criterion,\n",
    "            train_mb_size=train_mb_size,\n",
    "            train_epochs=train_epochs,\n",
    "            eval_mb_size=eval_mb_size,\n",
    "            device=device,\n",
    "            plugins=plugins,\n",
    "            evaluator=evaluator,\n",
    "            eval_every=eval_every,\n",
    "            **base_kwargs)\n",
    "        \n",
    "        \n",
    "    # The criterion function is overwritten to adapt the input to the VAE loss function,\n",
    "    def criterion(self):\n",
    "        return self._criterion(self.mb_x, self.mb_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630e9e9f",
   "metadata": {},
   "source": [
    "***\n",
    "### Generative Replay training class\n",
    "\n",
    "Experiment that defines the training strategy of **Generative Replay**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0d12c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerativeReplay(SupervisedTemplate):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # --- Strategy instantiation --- # \n",
    "        # 1. Model\n",
    "        # 2. Optimizer\n",
    "        # 3. Criterion\n",
    "        model: Module, optimizer: Optimizer, criterion=CrossEntropyLoss(),\n",
    "        # additional arguments\n",
    "        train_mb_size: int = 1,\n",
    "        train_epochs: int = 1,\n",
    "        eval_mb_size: int = None,\n",
    "        device=None,\n",
    "        plugins: Optional[List[SupervisedPlugin]] = None,\n",
    "        evaluator: EvaluationPlugin = default_evaluator,\n",
    "        eval_every=-1,\n",
    "        \n",
    "        # param: generator_strategy takes as input the VAE generator\n",
    "        generator_strategy: BaseTemplate = None,\n",
    "        \n",
    "        # replay data size to be concatenated to the current training batch\n",
    "        replay_size: int = None,\n",
    "        increasing_replay_size: bool = False, # double the amount of replay data added to each data batch\n",
    "        **base_kwargs):\n",
    "        \n",
    "        # any kind of generative model (implemented in GenerativeModel.py)\n",
    "        if generator_strategy is not None:\n",
    "            self.generator_strategy = generator_strategy\n",
    "\n",
    "        rp = GenerativeReplayPlugin(\n",
    "            generator_strategy=self.generator_strategy,\n",
    "            replay_size=replay_size,\n",
    "            increasing_replay_size=increasing_replay_size)\n",
    "        \n",
    "        tgp = TrainGeneratorAfterExpPlugin()\n",
    "\n",
    "        if plugins is None:\n",
    "            plugins = [tgp, rp]\n",
    "        else:\n",
    "            plugins.append(tgp)\n",
    "            plugins.append(rp)\n",
    "\n",
    "        super().__init__(\n",
    "            model, optimizer, criterion,\n",
    "            train_mb_size=train_mb_size,\n",
    "            train_epochs=train_epochs,\n",
    "            eval_mb_size=eval_mb_size,\n",
    "            device=device,\n",
    "            plugins=plugins,\n",
    "            evaluator=evaluator,\n",
    "            eval_every=eval_every,\n",
    "            **base_kwargs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
